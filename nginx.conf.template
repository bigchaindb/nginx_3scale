worker_processes 2;
daemon off;
user nobody nogroup;
pid /tmp/nginx.pid;
error_log /usr/local/openresty/nginx/logs/nginx.error.log;
env THREESCALE_DEPLOYMENT_ENV;

events {
  worker_connections 256;
  accept_mutex on;
  use epoll;
}

http {
  lua_shared_dict api_keys 10m;
  server_names_hash_bucket_size 128;
  lua_package_path ";;$prefix/?.lua;$prefix/conf/?.lua";
  init_by_lua 'math.randomseed(ngx.time()) ; cjson = require("cjson")';
  access_log /usr/local/openresty/nginx/logs/nginx.access.log combined buffer=16k flush=5s;

  # allow 10 req/sec from the same IP address, and store the counters in a
  # `zone` or shared memory location tagged as 'one'.
  limit_req_zone $binary_remote_addr zone=one:10m rate=10r/s;
  # enable logging when requests are being throttled
  limit_req_log_level notice;
  
  # the http status code to return to the client; 429 is for TooManyRequests,
  # ref. RFC 6585
  limit_req_status 429;
  
  resolver DNS_SERVER valid=30s;
  
  map $remote_addr $bdb_backend {
    default BIGCHAINDB_BACKEND_HOST;
  }
  
  upstream backend_SERVICE_ID {
    server localhost:UPSTREAM_API_PORT max_fails=5 fail_timeout=30;
  }
  
  # Our frontend API server that accepts requests from the external world and
  # takes care of authentication and authorization. If auth is successful, it
  # forwards the request to the backend_SERVICE_ID upstream where a consortium
  # can run a BDB cluster.
  server {
    lua_code_cache on;
    listen BIGCHAINDB_FRONTEND_PORT ssl;
    server_name "FRONTEND_DNS_NAME";

    ssl_certificate        /usr/local/openresty/nginx/conf/ssl/cert.pem;
    ssl_certificate_key    /usr/local/openresty/nginx/conf/ssl/cert.key;
    ssl_protocols          TLSv1 TLSv1.1 TLSv1.2;
    ssl_ciphers            HIGH:!aNULL:!MD5;
    keepalive_timeout 60s;

    underscores_in_headers on;
    set_by_lua $deployment 'return os.getenv("THREESCALE_DEPLOYMENT_ENV")';
    set $threescale_backend "https://su1.3scale.net";
    #set $threescale_backend "http://su1.3scale.net";
    #set $threescale_backend "https://su1.3scale.net:443";
    #set $threescale_backend "https://echo-api.3scale.net";
    
    # `slowloris` attack mitigation settings
    client_body_timeout 10s;
    client_header_timeout 10s;
    
    # 3scale api for both auth and reporting in a single API call.
    # We do not use it; this is code we get from the 3scale downloads.
    #location = /threescale_authrep {
    #  internal;
    #  set $provider_key "PROVIDER_KEY";
    #  proxy_pass $threescale_backend/transactions/authrep.xml?provider_key=$provider_key&service_id=$service_id&$usage&$credentials&log%5Bcode%5D=$arg_code&log%5Brequest%5D=$arg_req&log%5Bresponse%5D=$arg_resp;
    #
    #  proxy_set_header  Host  "su1.3scale.net";
    #  #proxy_set_header  Host  "echo-api.3scale.net";
    #
    #  proxy_set_header  X-3scale-User-Agent "nginx$deployment";
    #  proxy_set_header  X-3scale-Version  "THREESCALE_VERSION_HEADER";
    #}

    location = /out_of_band_authrep_action {
      internal;
      proxy_pass_request_headers off;
      set $provider_key "PROVIDER_KEY";
      content_by_lua "require('nginx').post_action_content()";
    }
    
    
    # 3scale auth api that takes the auth credentials and metrics as input,
    # and returns 200 OK if both the credentials match and the user has not
    # exceeded the limits in his application plan.
    location = /threescale_auth {
      internal;
      set $provider_key "PROVIDER_KEY";
      proxy_pass $threescale_backend/transactions/authorize.xml?provider_key=$provider_key&service_id=$service_id&$usage&$credentials&log%5Bcode%5D=$arg_code&log%5Brequest%5D=$arg_req&log%5Bresponse%5D=$arg_resp;
      proxy_set_header  Host  "su1.3scale.net";
      #proxy_set_header  Host  "echo-api.3scale.net";
      proxy_set_header  X-3scale-User-Agent "nginx$deployment";
      proxy_set_header  X-3scale-Version  "THREESCALE_VERSION_HEADER";
    }

    # 3scale reporting api that takes the metrics data and persists the metrics
    # in the 3scale backend.
    location = /threescale_report {
      internal;
      set $provider_key "PROVIDER_KEY";
      proxy_pass $threescale_backend/transactions.xml;
      proxy_set_header  Host  "su1.3scale.net";
      #proxy_set_header  Host  "echo-api.3scale.net";
      # We have a bug in lua-nginx module that does not set
      # Content-Type from lua script
      proxy_pass_request_headers off;
      proxy_set_header  Content-Type "application/x-www-form-urlencoded";
      proxy_set_header  X-3scale-User-Agent "nginx$deployment";
      proxy_set_header  X-3scale-Version  "THREESCALE_VERSION_HEADER";
    }

    location / {
      set $provider_key null;
      set $cached_key null;
      set $credentials null;
      set $usage null;
      set $service_id SERVICE_ID;
      set $proxy_pass null;
      set $secret_token null;
      set $resp_body null;
      set $resp_headers null;
      proxy_ignore_client_abort on;
      access_by_lua "require('nginx').access()";
      body_filter_by_lua  'ngx.ctx.buffered = (ngx.ctx.buffered or "") .. string.sub(ngx.arg[1], 1, 1000)
                           if ngx.arg[2] then ngx.var.resp_body = ngx.ctx.buffered end';
      header_filter_by_lua 'ngx.var.resp_headers = cjson.encode(ngx.resp.get_headers())';
      proxy_pass $proxy_pass ;
      proxy_set_header X-Real-IP  $remote_addr;
      proxy_set_header Host FRONTEND_DNS_NAME;
      proxy_set_header X-3scale-proxy-secret-token $secret_token;
      post_action /out_of_band_authrep_action;

      # limit requests from the same client, allow `burst` to 20 r/s,
      # `nodelay` or drop connection immediately in case it exceeds this
      # threshold.
      limit_req zone=one burst=20 nodelay;
    }
  }
  
  # Our backend server block that accepts requests from the nginx proxy and
  # forwards it to instances of BDB cluster. We currently run only a single
  # instance.
  server {
    sendfile on;
    listen UPSTREAM_API_PORT;
    # max client request body size: avg transaction size
    client_max_body_size 15k;

    # keepalive connection settings
    keepalive_timeout 60s;

    # `slowloris` attack mitigation settings
    client_body_timeout 10s;
    client_header_timeout 10s;
    
    if ( $http_x_3scale_proxy_secret_token != "THREESCALE_RESPONSE_SECRET_TOKEN" ) {
      return 403;
    }

    location / {
      try_files $uri @proxy_to_app;
    }

    location @proxy_to_app {
      proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
      # enable the following line if and only if you use HTTPS
      proxy_set_header X-Forwarded-Proto https;
      proxy_set_header Host $http_host;
      
      # we don't want nginx trying to do something clever with
      # redirects, we set the Host: header above already.
      proxy_redirect off;
      proxy_pass http://$bdb_backend:BIGCHAINDB_BACKEND_PORT;
      
      # limit requests from the same client, allow `burst` to 20 r/s on avg,
      # `nodelay` or drop connection immediately in case it exceeds this
      # threshold.
      limit_req zone=one burst=20 nodelay;
    }

    error_page 500 502 503 504 /50x.html;
    location = /50x.html {
      root /usr/local/openresty/nginx/html/50x.html;
    }
  }

  # health-check for LB
  server {
    listen HEALTH_CHECK_PORT;

    # `slowloris` attack mitigation settings
    client_body_timeout 10s;
    client_header_timeout 10s;

    location = /health {
      # limit requests from the same client, allow `burst` to 20 r/s on avg,
      # `nodelay` or drop connection immediately in case it exceeds this
      # threshold.
      limit_req zone=one burst=20 nodelay;

      return 200;
    }
  }

  server {
    listen 80;
    server_name "FRONTEND_DNS_NAME";
    location / {
        add_header Upgrade "TLS/1.2, HTTP/1.1" always;
        default_type text/plain;
        return 426 'Consider using the HTTPS protocol next time!';
    }
  }
}

# NGINX stream block for TCP and UDP proxies
# TODO(Krish): Uncomment after Openresty adds support for NGINX v1.11.3
#stream {
#  log_format mdb_log '[$time_iso8601] $realip_remote_addr $remote_addr '
#                     '$proxy_protocol_addr $proxy_protocol_port '
#                     '$protocol $status $session_time $bytes_sent '
#                     '$bytes_received "$upstream_addr" "$upstream_bytes_sent" '
#                     '"$upstream_bytes_received" "$upstream_connect_time" ';
#  
#  access_log /usr/local/openresty/nginx/logs/nginx.stream.access.log mdb_log buffer=16k flush=5s;
#  
#  # define a zone 'two' of size 10 megabytes to store the counters
#  # that hold number of TCP connections from a specific IP address
#  limit_conn_zone $binary_remote_addr zone=two:10m;
#
#  # enable logging when connections are being throttled
#  limit_conn_log_level notice;
#  
#  resolver DNS_SERVER valid=20s;
#
#  map $remote_addr $mdb_backend {
#    default MONGODB_BACKEND_HOST;
#  }
#  
#  server {
#    listen MONGODB_FRONTEND_PORT so_keepalive=10m:1m:5;
#    preread_timeout 30s;
#    tcp_nodelay on;
#    
#    # whitelist
#    MONGODB_WHITELIST
#    # deny access to everyone else
#    deny all;
#    
#    # allow 16 connections from the same IP address
#    limit_conn two 16;
#    
#    proxy_pass $mdb_backend:MONGODB_BACKEND_PORT;
#  }
#}

